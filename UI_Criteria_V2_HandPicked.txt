A- Global Pages
---------------
Navigation & Findability – Quick‑Score Guide
===========================================

1. Evaluation Summary
   - Assesses how quickly a new shopper can grasp site structure, move between key pages (home ⇄ category ⇄ product ⇄ cart), and locate a specific item.
   - Relies on obvious labels, visible search, sensible hierarchy, orientation cues (breadcrumbs), and clear recovery paths to cut friction and boost conversion.

------------------------------------------------------------

2. Scoring Criteria
   1. **Menu clarity & placement**
      • What to look for: Global nav visible on every page with plain‑language category names.  
      • How to judge: Hidden or cryptic labels lower score; obvious, self‑evident labels raise.

   2. **Hierarchy & grouping**
      • What to look for: Logical grouping, mega‑menu or sub‑menus sized to catalog.  
      • How to judge: Mis‑grouped or overly deep nesting penalizes.

   3. **Search bar visibility**
      • What to look for: Search field above the fold on all pages with hint text (“Search products…”).  
      • How to judge: Hard‑to‑spot, missing, or home‑only search lowers.

   4. **Search assistance**
      • What to look for: Autocomplete, spell‑check, suggestions speeding queries.  
      • How to judge: No assistive features deduct up to one point.

   5. **Orientation cues**
      • What to look for: Breadcrumbs or highlighted current section.  
      • How to judge: Absent cues lower confidence and score.

   6. **Error‑recovery paths**
      • What to look for: Logo‑to‑home link, “Back to results,” persistent cart link.  
      • How to judge: Dead‑ends or orphan pages cost points.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: User lost; menu absent/mislabeled; no search or buried search.  
      • Concrete example: URL “/products?id=123” shows no menu, no route back.

   2. **Poor (2)**
      • Quick diagnostic: Menu exists but vague (“Stuff”, “More”); minuscule footer search.  
      • Concrete example: Click “Accessories” expecting phone cases, land on unrelated gadgets.

   3. **Average (3)**
      • Quick diagnostic: Basic nav works; some labels off; breadcrumbs sporadic.  
      • Concrete example: “Electronics > Phones” path clear, but search only in desktop header.

   4. **Good (4)**
      • Quick diagnostic: Clear categories, prominent search, consistent breadcrumbs; minor tweaks left.  
      • Concrete example: Mega‑menu lists “Laptops”, “Tablets”, “Phones”; auto‑suggest shows top hits.

   5. **Excellent (5)**
      • Quick diagnostic: Instant catalog comprehension; well‑organized menus; smart search; flawless breadcrumbs.  
      • Concrete example: Apple.com‑like layout – omnipresent search, intuitive categories, no dead‑ends.

------------------------------------------------------------

How to Use
----------
1. Open the site and attempt three tasks:  
   • Browse to a flagship product.  
   • Search for an obscure SKU.  
   • Return to cart.  
2. Tick each criterion above; note any failures.  
3. Assign the score that best matches the “Quick Diagnostic” row.  
4. Add 1–2 sentences of evidence (“Search buried in footer; breadcrumbs missing – scored 2/Poor”).  

Visual Design & Aesthetics – Quick‑Score Guide
=============================================

1. Evaluation Summary
   - How visually appealing, modern, and trustworthy the page looks at first glance. 
   - Focus on layout balance, use of whitespace, harmonious color palette, clear typography, high‑quality imagery, and overall consistency.
   - Good design should draw attention to key elements (product photos, CTAs) while maintaining brand cohesion and readability.

------------------------------------------------------------

2. Scoring Criteria
   1. **Layout & whitespace**
      • What to look for: Balanced grid or modular layout with sufficient breathing space around elements.  
      • How to judge: Crowded, misaligned, or inconsistent spacing lowers the score; generous, well‑structured spacing raises it.

   2. **Typography clarity & size**
      • What to look for: Legible font choices, appropriate hierarchy of headings, body, and captions.  
      • How to judge: Tiny fonts, odd typefaces, or inconsistent heading styles reduce the score; clear, consistent type raises it.

   3. **Color scheme & contrast**
      • What to look for: Brand‑aligned palette, adequate contrast for readability, and restrained use of accent colors.  
      • How to judge: Clashing hues or poor contrast deduct points; harmonious palette with purposeful highlights adds points.

   4. **Imagery quality & relevance**
      • What to look for: High‑resolution product photos or lifestyle images that match the brand mood.  
      • How to judge: Pixelated, stretched, or generic stock images penalize; crisp, well‑lit, on‑brand visuals reward.

   5. **Visual hierarchy & emphasis**
      • What to look for: Clear focal points guiding the eye (F‑ or Z‑pattern), CTAs in contrasting colors.  
      • How to judge: Important elements lost in clutter or low contrast lower the score; obvious, intuitive emphasis raises it.

   6. **Styling consistency across pages**
      • What to look for: Same fonts, colors, button shapes, and icon styles throughout the site.  
      • How to judge: Random changes in style or outdated elements reduce trust and score; seamless consistency boosts it.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: Outdated look, clashing colors, unreadable text, low‑quality images; feels spammy or unsafe.  
      • Concrete example: Neon green text on dark red background, clip‑art graphics, and five different fonts in one view.

   2. **Poor (2)**
      • Quick diagnostic: Basic structure exists but cluttered with ads/pop‑ups; inconsistent fonts or misaligned sections.  
      • Concrete example: Homepage with three competing banners, two pop‑ups, and headings in different font families.

   3. **Average (3)**
      • Quick diagnostic: Clean enough and consistent, yet unremarkable; minor clutter or weak CTA emphasis.  
      • Concrete example: Acceptable grid and color scheme, but CTA button blends with other elements and whitespace feels tight.

   4. **Good (4)**
      • Quick diagnostic: Modern, well‑organized design; strong product imagery; clear CTA contrast; minor tweaks left.  
      • Concrete example: Plenty of whitespace, uniform font stack, large product photos; could use slightly bolder CTA style.

   5. **Excellent (5)**
      • Quick diagnostic: Polished, professional aesthetic that inspires trust instantly; perfect hierarchy and cohesive branding.  
      • Concrete example: High‑end fashion site with elegant typography, hi‑res editorial imagery, and a standout “Add to Cart” button.

------------------------------------------------------------

How to Use
----------
1. Open the page and take a five‑second “first‑impression” snapshot – note emotional response.  
2. Walk through each criterion above, marking issues or strengths.  
3. Match findings to the score descriptions (Very Poor → Excellent) and assign the most fitting score.  
4. Add one or two sentences citing evidence (“Images pixelated on hero banner; CTA blends into background – scored 2/Poor”).  

B - Landing page:
Visual Hierarchy & Focus – Landing Page Quick‑Score Guide
========================================================

1. Evaluation Summary
   - Measures how clearly and efficiently the landing page directs user attention to the most important elements (hero banner, primary CTA, featured categories).
   - A strong hierarchy presents a single dominant focal point, minimal competing distractions, and an intuitive flow from top‑priority content to supporting information.

------------------------------------------------------------

2. Scoring Criteria
   1. **Primary focal point clarity**
      • What to look for: One obvious hero/banner or headline that instantly tells users “Start here.”  
      • How to judge: Multiple competing banners or no standout element lowers the score; a single, unmistakable focal point raises it.

   2. **CTA prominence**
      • What to look for: Primary “Shop Now” (or equivalent) button stands out via color, size, or position.  
      • How to judge: CTA blending into background or overshadowed by lesser items deducts points.

   3. **Clutter control**
      • What to look for: Limited number of promotional modules, pop‑ups, animations, or sidebars.  
      • How to judge: Busy carousels, blinking offers, or dense ad areas reduce the score; restrained, purposeful content increases it.

   4. **Content grouping & flow**
      • What to look for: Logical sequencing—hero → key categories/promotions → supportive info, with clear spacing between sections.  
      • How to judge: Erratic eye jumps or mis‑grouped elements penalize; smooth vertical or F/Z‑pattern flow rewards.

   5. **Visual emphasis techniques**
      • What to look for: Size, color contrast, and whitespace used to rank importance.  
      • How to judge: All elements given equal weight lowers clarity; obvious hierarchy of text sizes, colors, and imagery boosts it.

   6. **Distraction management**
      • What to look for: Minimal auto‑play videos, aggressive pop‑ups, or secondary widgets drawing focus away from the main goal.  
      • How to judge: Frequent distractions lower the score; subtle or postponed secondary elements raise it.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: Page feels chaotic; many banners scream for attention or nothing stands out; user confused where to look.  
      • Concrete example: Five animated promotions, auto‑rotating carousel, and no clear CTA button in first viewport.

   2. **Poor (2)**
      • Quick diagnostic: Some structure but focus diluted by side elements or busy background; eyes jump between highlights.  
      • Concrete example: Hero banner exists but flanked by two sidebar promos of equal visual weight plus moving Instagram feed.

   3. **Average (3)**
      • Quick diagnostic: Clear main area but slightly crowded; a few extra promos or spacing issues; functional yet not optimal.  
      • Concrete example: Large banner with headline, three secondary promos directly underneath with similar visual weight.

   4. **Good (4)**
      • Quick diagnostic: Dominant hero, limited supplementary sections, strong CTA, ample whitespace; minor tweaks left.  
      • Concrete example: Full‑width seasonal sale banner, bold “Shop Now”, followed by three category tiles; no pop‑ups.

   5. **Excellent (5)**
      • Quick diagnostic: Clean, curated layout with one primary focus, restrained secondary elements, flawless flow; feels premium.  
      • Concrete example: Single immersive hero for new collection, standout CTA, minimal copy, and subtle scroll cue; no distractions.

------------------------------------------------------------

How to Use
----------
1. Load the homepage and note your eye’s first two stops within five seconds.  
2. Walk through each criterion above, listing distractions or strengths.  
3. Match observations to the score descriptions and assign 1–5.  
4. Record one‑sentence evidence (“Hero clear but sidebar promo competes with CTA – scored 3/Average”).  

Primary Call‑to‑Action (CTA) Effectiveness – Landing Page Quick‑Score Guide
===========================================================================

1. Evaluation Summary
   - Evaluates how obvious, compelling, and easy‑to‑interact‑with the landing page’s main CTA is.
   - Considers wording (clear benefit + action), visual distinction (button styling, contrast), placement in the page flow, and whether multiple CTAs compete or complement each other.
   - A focused, well‑designed CTA is the main lever for pushing visitors deeper into the shopping or sign‑up funnel.

------------------------------------------------------------

2. Scoring Criteria
   1. **Visibility & placement**
      • What to look for: CTA appears in the hero or other high‑attention area; repeated sensibly on longer pages.  
      • How to judge: CTA below the fold or buried in text lowers the score; above‑the‑fold, eye‑level placement raises it.

   2. **Wording & value clarity**
      • What to look for: Action‑oriented text that tells users what happens next or what they gain (“Shop the Sale”).  
      • How to judge: Generic labels (“Submit”, “Click Here”) or unclear benefits deduct points; specific, benefit‑oriented labels add points.

   3. **Visual distinction**
      • What to look for: Button styling (size, color, padding) that sets the CTA apart from surrounding content.  
      • How to judge: CTA blending with body text or low contrast reduces score; high contrast, ample white space increases it.

   4. **Hierarchy & lack of conflict**
      • What to look for: One primary CTA (or one per clear segment) with secondary actions visually subordinate.  
      • How to judge: Equal‑weight buttons or numerous competing CTAs cause choice paralysis and lower score; clear hierarchy boosts it.

   5. **Contextual support**
      • What to look for: CTA placed after or alongside persuasive copy, imagery, or value proposition.  
      • How to judge: CTA appearing before explanation or requiring excessive scroll detracts; logical, timely placement enhances.

   6. **Reinforcement & repetition strategy**
      • What to look for: CTA echoed at logical breakpoints on long pages without feeling spammy.  
      • How to judge: Missing secondary placements or excessive repetition (every screen) deduct; well‑timed repeats add.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: CTA missing, hidden, or lost among many buttons; user unsure how to proceed.  
      • Concrete example: Welcome text only; “Shop Now” buried in a carousel slide that rotates away.

   2. **Poor (2)**
      • Quick diagnostic: A CTA exists but label is vague or looks like plain text; odd placement; multiple equal buttons create confusion.  
      • Concrete example: “Submit” button in footer before any details; three identically styled CTAs for different actions.

   3. **Average (3)**
      • Quick diagnostic: Obvious “Shop Now” in hero with contrasting color; some secondary CTAs slightly distract; could be more prominent.  
      • Concrete example: Hero button stands out, but sidebar “Join Newsletter” link competes visually.

   4. **Good (4)**
      • Quick diagnostic: Action‑oriented, benefit‑driven label; strong design contrast; intuitive placement; minimal competing links.  
      • Concrete example: Bold “Get 10% Off – Shop Sale” button front‑and‑center, repeated once mid‑page.

   5. **Excellent (5)**
      • Quick diagnostic: Singular, irresistible CTA aligned with business goal; perfect contrast; directional cues; zero conflict.  
      • Concrete example: Fullscreen hero with “Claim Your Discount” button, arrow icon drawing eye, nav minimized; second identical button near fold.

------------------------------------------------------------

How to Use
----------
1. Open landing page and note: “Can I tell what to click in three seconds?”  
2. Walk through each criterion, flagging weaknesses or strengths.  
3. Match observations to score descriptions (1–5) and assign the closest fit.  
4. Record one evidence sentence (“CTA label vague and below fold – scored 2/Poor”).  

Product Discovery & Category Highlights – Landing Page Quick‑Score Guide
========================================================================

1. Evaluation Summary
   - Examines how effectively the homepage exposes users to the breadth of the catalog and offers clear, enticing pathways into key categories, promotions, or featured products.
   - Focus is on visibility, relevance, organization, and inspiration: does the page feel like a curated storefront window that quickly answers “What can I shop here?” and nudges users toward popular or strategic sections?

------------------------------------------------------------

2. Scoring Criteria
   1. **Category visibility & labeling**
      • What to look for: Prominent tiles, links, or icons for major product categories with concise, intuitive names.  
      • How to judge: Omitted or cryptic category links lower score; clearly labeled, visually distinct categories raise it.

   2. **Strategic prioritization**
      • What to look for: Highlighted categories/products align with seasonality, popularity, or business goals (e.g., high‑margin, new arrivals).  
      • How to judge: Random or niche first impressions deduct points; timely, high‑interest selections add points.

   3. **Layout clarity & balance**
      • What to look for: Clean grid, carousel, or sectioned layout that avoids overwhelming lists.  
      • How to judge: Massive unstructured link lists or cluttered promo blocks reduce score; balanced presentation boosts it.

   4. **Featured product enticement**
      • What to look for: High‑quality images and clear context (e.g., “Trending”, “New In”) for showcased items.  
      • How to judge: Low‑resolution images or unlabeled product grids detract; compelling imagery and labels enhance.

   5. **Guidance to next step**
      • What to look for: Obvious CTAs or links within each highlighted area directing users deeper (e.g., “Shop Electronics”).  
      • How to judge: Category tile without follow‑up link or vague “Learn More” lowers score; direct, action‑oriented links raise it.

   6. **Personalization / discovery aids (advanced)**
      • What to look for: Dynamic recommendations, quizzes, or search examples that tailor discovery.  
      • How to judge: None expected for mid‑tier sites, but presence of smart aids can lift score to top tier.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: No category showcase; homepage is a generic welcome with no product glimpses or only one vague “Browse Catalog” link.  
      • Concrete example: Full‑screen hero video, minimal text, no tiles or product images; user must open nav to see categories.

   2. **Poor (2)**
      • Quick diagnostic: Attempts at discovery but ineffective—oversized list of 30 text links or irrelevant categories; little context.  
      • Concrete example: Sidebar list “Stationery, Pet Supplies, Car Parts…” with no images; hard to know where to start.

   3. **Average (3)**
      • Quick diagnostic: Basic grid of 6–8 main categories or a “Featured Products” row; adequate but not strategic or comprehensive.  
      • Concrete example: Tiles for “Men”, “Women”, “Kids”, but missing popular “Sale” or “New In” sections.

   4. **Good (4)**
      • Quick diagnostic: Well‑designed section for top categories, plus “Trending” or seasonal promo; visually appealing and organized.  
      • Concrete example: Three large tiles (“Spring Sale”, “Electronics”, “Home & Garden”) with clear imagery and CTAs, plus “New Arrivals” carousel.

   5. **Excellent (5)**
      • Quick diagnostic: Curated mix of popular, new, and seasonal highlights; possibly personalized; interactive aids guide every shopper.  
      • Concrete example: Personalized “Recommended for You” strip, major category tiles with sub‑links, holiday gift guide banner—all harmonious and uncluttered.

------------------------------------------------------------

How to Use
----------
1. Open the homepage and ask: “Can I immediately see at least one category or product that interests me?”  
2. Evaluate each criterion, noting gaps (e.g., missing high‑value category, cluttered link list).  
3. Match observations to the score descriptions (1–5) and select the closest fit.  
4. Document a short rationale (“Categories well‑labeled but layout cluttered – scored 3/Average”).  

C- search pages

Product Listing Content & Information Density – Search Results Quick‑Score Guide
================================================================================

1. Evaluation Summary
   - Rates how much and how well information is presented on each product card in the results list.
   - Balances completeness (name, image, price, variations, ratings, stock, promos) against scannability—enough details to compare, no overwhelming clutter.
   - Well‑tuned listings let shoppers shortlist accurately, raising click‑through quality and conversion.

------------------------------------------------------------

2. Scoring Criteria
   1. **Essential info completeness**
      • What to look for: Every product shows at minimum a clear image, full name, and price.  
      • How to judge: Missing any of these for some items lowers the score; consistently present raises it.

   2. **Helpful add‑ons**
      • What to look for: Ratings, review count, promo badges (“Sale”, “New”), free‑shipping tag, urgency (“Only 2 left”).  
      • How to judge: Lack of relevant cues deducts points; thoughtful, concise extras add points.

   3. **Variation indicators**
      • What to look for: Color swatches, “5 sizes”, or text hinting multiple options when important to purchase.  
      • How to judge: No hint about variants that matter lowers score; clear, space‑saving indicators raise it.

   4. **Visual clarity & consistency**
      • What to look for: Adequate image size, proper cropping, readable titles (no excessive truncation).  
      • How to judge: Tiny or misaligned images, cut‑off names, inconsistent layouts reduce score; crisp, uniform cards add points.

   5. **Information density & layout**
      • What to look for: Clean card/grid with hierarchy—key data emphasized, secondary info subdued.  
      • How to judge: Overly busy cards or massive whitespace deduct; balanced text/icon mix boosts.

   6. **Decision aids / interactivity (advanced)**
      • What to look for: Quick‑view, add‑to‑cart or wishlist from listing, hover zoom, compare checkbox.  
      • How to judge: Absent is fine for mid‑tier scores; well‑implemented aids can lift to top tier.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: Only product names as links or name + image, no price; user must click each item blindly.  
      • Concrete example: Text list of “Model A”, “Model B” with no photos or prices.

   2. **Poor (2)**
      • Quick diagnostic: Image, name, price for some items; missing or inconsistent info; small, unclear images.  
      • Concrete example: Half the TVs show price, others “See price in cart”; ratings absent; thumbnails tiny.

   3. **Average (3)**
      • Quick diagnostic: Image, full name, price on all items; maybe basic star rating; scannable but minimal extras.  
      • Concrete example: Clothing grid with photo, title, price; no color or size hints.

   4. **Good (4)**
      • Quick diagnostic: Clear images, descriptive titles, price + discounts, ratings, variant hints; uncluttered layout.  
      • Concrete example: Laptop listings with large photo, “13‑inch, 256 GB”, price + “SAVE 15%”, ★4.5 and review count.

   5. **Excellent (5)**
      • Quick diagnostic: Rich yet clean cards—price, discount %, ratings, stock/urgency, variant swatches, quick‑view/add‑to‑cart; still easy to scan.  
      • Concrete example: Sneakers grid with hover quick‑view, color dots, “Only 2 left!”, strike‑through old price, ★4.8; card stays tidy.

------------------------------------------------------------

How to Use
----------
1. Scan results page and ask, “Do I have enough info to pick which item to click without guessing?”  
2. Walk the six criteria, jotting missing or excessive details.  
3. Compare with score descriptions and assign 1–5.  
4. Note concise evidence (“No prices on half the items – scored 2/Poor”).  


Filtering & Sorting Functionality – Search Results Quick‑Score Guide
===================================================================

1. Evaluation Summary
   - Measures how completely and effortlessly users can narrow or reorder a long list of products.
   - Focus areas: breadth and relevance of filters, ease of interaction (multi‑select, instant update), visibility of active filters, result counts, and variety of sort options.
   - Effective tools shorten time‑to‑product, reduce frustration, and drive higher conversion.

------------------------------------------------------------

2. Scoring Criteria
   1. **Filter range & relevance**
      • What to look for: Facets that match the product category (e.g., size, color for apparel; brand, screen size for TVs).  
      • How to judge: Missing key facets lowers score; comprehensive, context‑specific facets raise it.

   2. **Filter UI usability**
      • What to look for: Familiar controls (checkboxes, sliders), clear labels, ability to multi‑select and combine filters.  
      • How to judge: One‑at‑a‑time selection or hard‑to‑tap controls deduct; intuitive multi‑select adds.

   3. **Speed & feedback**
      • What to look for: Instant or AJAX updates, visible loading indicators, real‑time result counts.  
      • How to judge: Full page reloads or no feedback lower score; live counts & instant refresh raise.

   4. **Active filter management**
      • What to look for: Tags, chips, or summary bar showing applied filters with easy remove/reset actions.  
      • How to judge: Hidden active filters or complex removal penalize; clear, one‑click removal boosts.

   5. **Sorting breadth & clarity**
      • What to look for: Options for price, newest, popularity, rating, etc., via dropdown or buttons.  
      • How to judge: Only one sort criterion or confusing labels lower score; diverse, obvious options raise.

   6. **Advanced aids (top‑tier)**
      • What to look for: Search within filters, adaptive facets, disabling zero‑result options, remembered sort prefs.  
      • How to judge: Absence fine for mid‑tier; presence of smart aids can elevate to level 5.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: No filters or sorting; user must scroll through hundreds of items.  
      • Concrete example: Results list 1,000 phones with no sidebar or sort dropdown.

   2. **Poor (2)**
      • Quick diagnostic: Few generic filters, clunky interface, single‑select only, slow reloads; limited sort.  
      • Concrete example: Dropdown “Brand” resets page on each pick; only “Price” sort available.

   3. **Average (3)**
      • Quick diagnostic: Standard multi‑select filters and basic sorts; page reload on apply; counts after filtering.  
      • Concrete example: Sidebar with size, color, price; click “Apply” reloads page; sort by price or newest.

   4. **Good (4)**
      • Quick diagnostic: Comprehensive, instant filters with result counts; removable filter tags; several sort options.  
      • Concrete example: Check three colors & one size, list updates instantly; dropdown sort by rating, popularity, price.

   5. **Excellent (5)**
      • Quick diagnostic: Adaptive, real‑time filters with live counts, search‑within‑facet, zero‑result options disabled; remembers sort.  
      • Concrete example: Electronics results show only relevant specs filters, live counts update as user types “128 GB” in storage filter search; sticky sort bar remembers “Lowest price”.

------------------------------------------------------------

How to Use
----------
1. Load search results; count how many steps to narrow to a desired subset.  
2. Walk through criteria noting gaps (e.g., no rating sort, filters reload page).  
3. Compare observations with score levels and assign 1–5.  
4. Record short evidence (“Filters instant but missing size facet – scored 3/Average”).  
Filtering & Sorting Functionality – Search Results Quick‑Score Guide
===================================================================

1. Evaluation Summary
   - Measures how completely and effortlessly users can narrow or reorder a long list of products.
   - Focus areas: breadth and relevance of filters, ease of interaction (multi‑select, instant update), visibility of active filters, result counts, and variety of sort options.
   - Effective tools shorten time‑to‑product, reduce frustration, and drive higher conversion.

------------------------------------------------------------

2. Scoring Criteria
   1. **Filter range & relevance**
      • What to look for: Facets that match the product category (e.g., size, color for apparel; brand, screen size for TVs).  
      • How to judge: Missing key facets lowers score; comprehensive, context‑specific facets raise it.

   2. **Filter UI usability**
      • What to look for: Familiar controls (checkboxes, sliders), clear labels, ability to multi‑select and combine filters.  
      • How to judge: One‑at‑a‑time selection or hard‑to‑tap controls deduct; intuitive multi‑select adds.

   3. **Speed & feedback**
      • What to look for: Instant or AJAX updates, visible loading indicators, real‑time result counts.  
      • How to judge: Full page reloads or no feedback lower score; live counts & instant refresh raise.

   4. **Active filter management**
      • What to look for: Tags, chips, or summary bar showing applied filters with easy remove/reset actions.  
      • How to judge: Hidden active filters or complex removal penalize; clear, one‑click removal boosts.

   5. **Sorting breadth & clarity**
      • What to look for: Options for price, newest, popularity, rating, etc., via dropdown or buttons.  
      • How to judge: Only one sort criterion or confusing labels lower score; diverse, obvious options raise.

   6. **Advanced aids (top‑tier)**
      • What to look for: Search within filters, adaptive facets, disabling zero‑result options, remembered sort prefs.  
      • How to judge: Absence fine for mid‑tier; presence of smart aids can elevate to level 5.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: No filters or sorting; user must scroll through hundreds of items.  
      • Concrete example: Results list 1,000 phones with no sidebar or sort dropdown.

   2. **Poor (2)**
      • Quick diagnostic: Few generic filters, clunky interface, single‑select only, slow reloads; limited sort.  
      • Concrete example: Dropdown “Brand” resets page on each pick; only “Price” sort available.

   3. **Average (3)**
      • Quick diagnostic: Standard multi‑select filters and basic sorts; page reload on apply; counts after filtering.  
      • Concrete example: Sidebar with size, color, price; click “Apply” reloads page; sort by price or newest.

   4. **Good (4)**
      • Quick diagnostic: Comprehensive, instant filters with result counts; removable filter tags; several sort options.  
      • Concrete example: Check three colors & one size, list updates instantly; dropdown sort by rating, popularity, price.

   5. **Excellent (5)**
      • Quick diagnostic: Adaptive, real‑time filters with live counts, search‑within‑facet, zero‑result options disabled; remembers sort.  
      • Concrete example: Electronics results show only relevant specs filters, live counts update as user types “128 GB” in storage filter search; sticky sort bar remembers “Lowest price”.

------------------------------------------------------------

How to Use
----------
1. Load search results; count how many steps to narrow to a desired subset.  
2. Walk through criteria noting gaps (e.g., no rating sort, filters reload page).  
3. Compare observations with score levels and assign 1–5.  
4. Record short evidence (“Filters instant but missing size facet – scored 3/Average”).  

D- Product page

Product Information & Description Quality – Product Page Quick‑Score Guide
===========================================================================

1. Evaluation Summary
   - Assesses how thoroughly and clearly the product page explains the item: description narrative, spec list, size/dimension info, materials, usage, unique selling points, and supporting assets.
   - Evaluates clarity of writing, logical organization (tabs, bullets, accordions), and accessibility of every detail a shopper needs to feel confident.

------------------------------------------------------------

2. Scoring Criteria
   1. **Core detail completeness**
      • What to look for: Title, descriptive paragraph, key specs (size, material, function), price and what’s included.  
      • How to judge: Missing any core detail lowers score; fully covered basics raise it.

   2. **Organization & readability**
      • What to look for: Logical sections (Description, Specs, Reviews, Q&A), bulleted lists, headings.  
      • How to judge: Wall‑of‑text or scattered info deduct; tidy sections & bullets add.

   3. **Clarity & tone**
      • What to look for: Jargon‑free language, concise yet informative, benefits highlighted.  
      • How to judge: Marketing fluff or tech jargon without explanation reduces; clear, user‑centric copy boosts.

   4. **Depth of specifications / FAQs**
      • What to look for: Detailed spec table, size charts, compatibility notes, care instructions.  
      • How to judge: Key specs omitted or vague deduct; thorough spec coverage raise.

   5. **Differentiators & unique selling points**
      • What to look for: Highlights of what makes this product stand out (e.g., eco‑friendly, patented tech).  
      • How to judge: No differentiation info lowers; clear USPs elevate.

   6. **Supplementary assets**
      • What to look for: Manuals, ingredient lists, comparison charts, downloadable guides.  
      • How to judge: None expected for mid‑tier; rich assets can push to top tier.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: Title + single vague sentence; no specs, sizes, or materials.  
      • Concrete example: “Handbag – stylish and durable.” (no dimensions, material, pockets info).

   2. **Poor (2)**
      • Quick diagnostic: Short paragraph but missing critical details or buried deep; jargon heavy.  
      • Concrete example: Laptop page lists CPU but no RAM/storage; specs hidden in collapsed section below fold.

   3. **Average (3)**
      • Quick diagnostic: Basic paragraph + bullet specs covering size, material, main features; no extras.  
      • Concrete example: T‑shirt page lists fabric, available sizes, care instructions; no size chart image.

   4. **Good (4)**
      • Quick diagnostic: Engaging description, full spec table, size chart, compatibility notes; clear layout.  
      • Concrete example: Camera page with bullet USPs, detailed specs tab, downloadable manual link.

   5. **Excellent (5)**
      • Quick diagnostic: Comprehensive multi‑section info incl. highlights, spec table, FAQs, comparison chart, manuals; easy to scan.  
      • Concrete example: High‑end phone page with “Top 5 features” bullets, full tech sheet, “Compare models” chart, warranty PDF.

------------------------------------------------------------

How to Use
----------
1. Read product page and ask, “Do I have every detail needed to purchase confidently?”  
2. Check each criterion, marking gaps (e.g., missing size chart).  
3. Match to score levels and assign 1–5.  
4. Log concise rationale (“Specs complete but lacks differentiator – scored 4/Good”).  

Product Imagery & Media – Product Page Quick‑Score Guide
=======================================================

1. Evaluation Summary
   - Evaluates the quality, variety, and usability of visual assets: high‑resolution photos, multiple angles, context shots, zoom, video, 360°/AR, and the gallery UI.
   - Goal: give shoppers an in‑store‑like view so they can judge color, texture, size, and feel confident to buy.

------------------------------------------------------------

2. Scoring Criteria
   1. **Image quality & resolution**
      • What to look for: Sharp, professional photos that stay clear on zoom or large screens.  
      • How to judge: Grainy or pixelated images lower score; crisp, high‑res images raise.

   2. **Angle & context variety**
      • What to look for: Multiple views (front, side, back, detail) plus in‑context or lifestyle shots.  
      • How to judge: Only one or two similar shots deduct; rich angle set, context images add.

   3. **Zoom & enlarge functionality**
      • What to look for: Click or hover zoom with high‑detail view; intuitive to exit.  
      • How to judge: No zoom or low‑res zoom lowers; seamless, deep zoom raises.

   4. **Supplementary media**
      • What to look for: Video demos, 360° spin, 3D model, AR preview where relevant.  
      • How to judge: None fine for mid‑tier; well‑integrated video/360 ° lifts to higher.

   5. **Gallery UI & accessibility**
      • What to look for: Clear thumbnails, swipe/arrow navigation, alt text for images, fast loading.  
      • How to judge: Hidden thumbnails or clunky navigation deduct; smooth, accessible gallery boosts.

   6. **Answering visual questions**
      • What to look for: Images that show scale, contents of box, texture close‑ups, color options.  
      • How to judge: Missing visual answers lowers; thoughtfully selected images raise.

------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

   1. **Very Poor (1)**
      • Quick diagnostic: One low‑res image, no zoom, no context.  
      • Concrete example: Small grainy photo of handbag, no inside view.

   2. **Poor (2)**
      • Quick diagnostic: Few mediocre images, missing key angles, no zoom or weak zoom.  
      • Concrete example: Front and back of jacket only, can’t view fabric texture.

   3. **Average (3)**
      • Quick diagnostic: 3–5 clear images covering main angles, basic click‑to‑enlarge.  
      • Concrete example: Phone shown front, back, side, close‑up of camera; basic lightbox.

   4. **Good (4)**
      • Quick diagnostic: High‑res, many angles + context shots, strong zoom, maybe a demo video.  
      • Concrete example: Blender gallery with 360° spin, video making smoothie, scale image on countertop.

   5. **Excellent (5)**
      • Quick diagnostic: Immersive visuals—plentiful hi‑res images, 360°, HD video, AR/3D, flawless gallery UI.  
      • Concrete example: Sneakers with hover zoom, color selector updating images, catwalk video, AR try‑on link.

------------------------------------------------------------

How to Use
----------
1. Browse the gallery—ask, “Can I see everything I’d check in store?”  
2. Check each criterion, listing missing media or UI issues.  
3. Compare to score levels and assign 1–5.  
4. Note evidence (“No context shots, weak zoom – scored 2/Poor”).  

Product Cart – Quick‑Score Guide
================================

(Combines Pricing & Availability, CTA & Purchase Controls, and Related/Cross‑Selling)

1. Evaluation Summary
   - Measures how clearly the product page communicates *cost*, *stock*, and *purchase actions*, and how effectively it encourages completing – or expanding – the cart through smart recommendations.
   - Focus spans three pillars:
     • **Price & Availability** – Transparent cost, discounts, stock status, variant‑aware updates.  
     • **Add‑to‑Cart Experience** – Prominent CTA, smooth option selection, instant feedback.  
     • **Cross‑Sell & Alternatives** – Relevant suggestions or bundles that aid decision and raise order value.

--------------------------------------------------------------------

2. Scoring Criteria
   1. **Price clarity & savings visibility**
      • High‑contrast price near title; sale strikes/percent saved; no hidden costs.

   2. **Availability & urgency cues**
      • Clear “In stock / Out of stock / Pre‑order” plus low‑stock or delivery estimates.

   3. **Variant‑aware updates**
      • Price and stock change instantly when size/color is chosen; unavailable combos disabled.

   4. **CTA prominence & usability**
      • Stand‑out “Add to Cart” (or Buy Now), logical placement, accessible on mobile; guidance before enabling.

   5. **Selection & quantity controls**
      • Intuitive swatches/drop‑downs, easy +/- quantity, graceful error prevention.

   6. **Post‑add feedback**
      • Immediate confirmation (mini‑cart, toast, count update) with path to checkout.

   7. **Relevancy of related/cross‑sell items**
      • Suggestions logically tied to current product (alternatives, accessories, bundles).

   8. **Cross‑sell UI & actionability**
      • Visually separate section, easy scroll/arrow nav, one‑click add or quick‑view.

   9. **Advanced personalization / fulfillment info (top tier)**
      • Store‑level availability, location‑based delivery ETA, personalized recs, financing/bundle promos.

--------------------------------------------------------------------

3. Score (1–5) with Example Benchmarks

1. **Very Poor (1)**
   • Price hidden until cart; no stock info; tiny or missing Add button; no related items.  
   • Example: “Add to cart to see price”; user discovers “Out of stock” at checkout.

2. **Poor (2)**
   • Price shown but small; unclear sale context; Add button hard to spot; few irrelevant “Popular” products.  
   • Example: Grey “Add” link below fold; variant pick then error “select size”; suggestion shows random phone case on dress page.

3. **Average (3)**
   • Clear price + basic sale strike‑through; in‑stock label; prominent Add button; variant prompts; generic “You May Also Like” carousel.  
   • Example: Shoe page with price update after size pick, standard cart pop‑up, similar shoes list beneath.

4. **Good (4)**
   • Bold price with savings; low‑stock or delivery notice; sticky Add CTA; variant swatches disable when unavailable; relevant accessories bundle.  
   • Example: Laptop page shows “Only 3 left”, Add button sticks on scroll, bundle “Laptop + Sleeve + Mouse – Add All”.

5. **Excellent (5)**
   • Dynamic price/stock per location, live delivery countdown; micro‑interaction Add button; instant cart overlay; AI‑driven alternatives & complementary items with one‑click add; financing & free shipping badges.  
   • Example: Camera page: “Order in 01:22:57 to receive Friday”; color pick updates price instantly; mini‑cart slides in; “Frequently bought together” adds kit in one click.

--------------------------------------------------------------------

How to Use
----------
1. Examine product page: Can I see price, stock, and clear Add button within first glance?  
2. Step through the nine criteria, noting gaps or strengths.  
3. Match findings to score descriptions and assign 1–5.  
4. Write brief evidence (“Low‑stock cue + bundle, but price small on mobile – scored 4/Good”).  
